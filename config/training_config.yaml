# Training configuration for finetuning GPT-OSS
model:
  name: "gpt-oss"
  max_length: 2048

training:
  learning_rate: 2e-4
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 1
  gradient_checkpointing: True
  num_train_epochs: 1
  warmup_ratio: 0.03
  
scheduler:
  lr_scheduler_type: "cosine_with_min_lr"
  lr_scheduler_kwargs:
    min_lr_rate: 0.1

logging:
  logging_steps: 1
  report_to: "mlflow"
  run_name: "gpt-oss-20b-multilingual-reasoner"

output:
  output_dir: "results/gpt-oss-20b-multilingual-reasoner"
  push_to_hub: false